# Configuraci√≥n de IA para FinSmart

## üìã Opciones de Modelos de IA

Para el procesamiento de lenguaje natural en el bot de Telegram, tenemos varias opciones:

---

## üöÄ Opci√≥n 1: Ollama (Recomendado - Local y Gratuito)

Ollama permite ejecutar modelos de IA potentes localmente sin necesidad de internet ni APIs externas.

### Paso 1: Descargar Ollama

1. Ve a [https://ollama.com/download](https://ollama.com/download)
2. Descarga la versi√≥n para Windows
3. Ejecuta el instalador `OllamaSetup.exe`
4. Sigue el asistente de instalaci√≥n

### Paso 2: Verificar la instalaci√≥n

```powershell
# Abre PowerShell y verifica que Ollama est√© instalado
ollama --version
```

### Paso 3: Descargar modelos

**Para procesamiento de lenguaje general (recomendado):**
```powershell
# Llama 3.2 (3B) - Ligero y r√°pido
ollama pull llama3.2

# O Llama 3.1 (8B) - M√°s potente pero requiere m√°s RAM
ollama pull llama3.1
```

**Para an√°lisis financiero espec√≠fico:**
```powershell
# Mistral - Excelente para razonamiento
ollama pull mistral

# Gemma - Optimizado de Google
ollama pull gemma2:9b
```

**Para espa√±ol:**
```powershell
# Llama 3.2 funciona bien en espa√±ol
ollama pull llama3.2

# Alternativa especializada en espa√±ol
ollama pull bge-m3
```

### Paso 4: Probar el modelo

```powershell
# Iniciar chat interactivo
ollama run llama3.2

# Probar con un prompt de prueba
# Escribe: "Hola, ay√∫dame a categorizar este gasto: compr√© pizza por $15"
# Para salir: /bye
```

### Paso 5: Integraci√≥n con Python

**Instalar la librer√≠a de Ollama:**
```powershell
pip install ollama
```

**C√≥digo de ejemplo:**
```python
import ollama

response = ollama.chat(
    model='llama3.2',
    messages=[{
        'role': 'user',
        'content': 'Categoriza este gasto: compr√© pizza por $15'
    }]
)

print(response['message']['content'])
```

### Requisitos del Sistema
- **RAM:** M√≠nimo 8GB (16GB recomendado)
- **Espacio en disco:** 4-10GB por modelo
- **Procesador:** Intel/AMD moderno (GPU opcional para mejor rendimiento)

---

## üåê Opci√≥n 2: OpenAI API (GPT)

M√°s potente pero requiere conexi√≥n a internet y tiene costo.

### Paso 1: Crear cuenta en OpenAI

1. Ve a [https://platform.openai.com/signup](https://platform.openai.com/signup)
2. Reg√≠strate con tu email
3. Verifica tu cuenta

### Paso 2: Obtener API Key

1. Ve a [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)
2. Click en "Create new secret key"
3. Copia la clave (solo se muestra una vez)
4. Gu√°rdala en tu archivo `.env`:
   ```
   OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxx
   ```

### Paso 3: Instalar librer√≠a

```powershell
pip install openai
```

### Paso 4: C√≥digo de ejemplo

```python
from openai import OpenAI

client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

response = client.chat.completions.create(
    model="gpt-4o-mini",  # M√°s econ√≥mico
    messages=[
        {"role": "system", "content": "Eres un asistente financiero experto"},
        {"role": "user", "content": "Categoriza este gasto: compr√© pizza por $15"}
    ]
)

print(response.choices[0].message.content)
```

### Costos aproximados (GPT-4o-mini):
- **Input:** $0.15 por 1M tokens
- **Output:** $0.60 por 1M tokens
- ~$0.01 por cada 100 mensajes t√≠picos

---

## ü§ó Opci√≥n 3: Hugging Face (Modelos especializados)

Modelos espec√≠ficos para tareas financieras.

### Paso 1: Instalar librer√≠as

```powershell
pip install transformers torch sentencepiece
```

### Paso 2: C√≥digo de ejemplo

```python
from transformers import pipeline

# Clasificador de texto para categorizaci√≥n
classifier = pipeline(
    "zero-shot-classification",
    model="facebook/bart-large-mnli"
)

texto = "Compr√© pizza por $15"
categorias = ["comida", "transporte", "entretenimiento", "servicios"]

result = classifier(texto, categorias)
print(f"Categor√≠a: {result['labels'][0]}")
```

---

## üìä Comparaci√≥n de Opciones

| Caracter√≠stica | Ollama | OpenAI | Hugging Face |
|----------------|--------|--------|--------------|
| **Costo** | Gratis | De pago | Gratis |
| **Internet** | No requiere | Requiere | No requiere |
| **Potencia** | Media-Alta | Muy Alta | Media |
| **Privacidad** | Total | Limitada | Total |
| **Facilidad** | Media | Alta | Baja |
| **Latencia** | Baja | Media | Baja |
| **Espa√±ol** | Bueno | Excelente | Variable |

---

## üéØ Recomendaci√≥n para FinSmart

**Para desarrollo/POC:** Ollama con Llama 3.2
- Gratis y sin l√≠mites
- Funciona offline
- Bueno para espa√±ol
- Datos privados

**Para producci√≥n:** Combinaci√≥n h√≠brida
- Ollama para categorizaci√≥n simple
- OpenAI para an√°lisis complejos y reportes
- Fallback entre ambos

---

## üîß Integraci√≥n con el Bot de Telegram

### Archivo: `POC/ai_processor.py`

```python
import ollama
import os
from typing import Dict, Any

class AIProcessor:
    def __init__(self, model: str = "llama3.2"):
        self.model = model
    
    def categorize_transaction(self, text: str) -> Dict[str, Any]:
        """Categoriza una transacci√≥n usando IA"""
        prompt = f"""
        Analiza esta transacci√≥n y extrae:
        - Monto (n√∫mero)
        - Categor√≠a (comida, transporte, entretenimiento, servicios, salud, otros)
        - Descripci√≥n breve
        
        Transacci√≥n: {text}
        
        Responde en formato JSON.
        """
        
        response = ollama.chat(
            model=self.model,
            messages=[{
                'role': 'user',
                'content': prompt
            }]
        )
        
        return response['message']['content']
    
    def financial_advice(self, balance: float, expenses: float) -> str:
        """Genera consejo financiero personalizado"""
        prompt = f"""
        Basado en estos datos financieros:
        - Balance: ${balance}
        - Gastos mensuales: ${expenses}
        
        Da un consejo financiero breve y pr√°ctico en espa√±ol.
        """
        
        response = ollama.chat(
            model=self.model,
            messages=[{
                'role': 'system',
                'content': 'Eres un asesor financiero experto.'
            }, {
                'role': 'user',
                'content': prompt
            }]
        )
        
        return response['message']['content']

# Uso:
# ai = AIProcessor()
# result = ai.categorize_transaction("gast√© 50 pesos en uber")
```

---

## üìù Pr√≥ximos Pasos

1. ‚úÖ Instalar Ollama
2. ‚úÖ Descargar modelo Llama 3.2
3. ‚úÖ Probar con ejemplos
4. ‚¨ú Integrar con el bot de Telegram
5. ‚¨ú Crear prompts espec√≠ficos para finanzas
6. ‚¨ú Agregar cach√© de respuestas frecuentes
7. ‚¨ú Implementar an√°lisis de sentimiento
8. ‚¨ú Crear reportes autom√°ticos con IA

---

## üêõ Troubleshooting

**Error: "ollama not found"**
- Reinicia PowerShell despu√©s de la instalaci√≥n
- Verifica que Ollama est√© en el PATH

**Modelo muy lento:**
- Usa un modelo m√°s peque√±o (llama3.2 en lugar de llama3.1:70b)
- Considera usar GPU si est√° disponible

**Respuestas en ingl√©s:**
- Especifica en el prompt: "Responde en espa√±ol"
- Usa modelos entrenados en espa√±ol

**Error de memoria:**
- Cierra otras aplicaciones
- Usa modelos m√°s peque√±os
- Aumenta la RAM del sistema
